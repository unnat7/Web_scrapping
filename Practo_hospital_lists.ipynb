from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.chrome.service import Service
from bs4 import BeautifulSoup
import time
import requests
import pandas as pd

def continuous_scroll(driver):
    for _ in range(500):  # Scroll down 10 times
        print(_)
        actions = ActionChains(driver)
        actions.send_keys(Keys.PAGE_DOWN).perform()
        time.sleep(2)  # Adjust the scrolling pace as necessary  

# URL of the website to scrape
url = "https://www.practo.com/hyderabad/clinics"

# Initialize the Chrome driver
service = Service('/Users/eloelo/Downloads/chromedriver')  # Path to your chromedriver
driver = webdriver.Chrome(service=service)

# Open the website
driver.get(url)

# Perform continuous scrolling
continuous_scroll(driver)

# Get the HTML content of the page after scrolling
html_content = driver.page_source

soup500 = BeautifulSoup(html_content, 'html.parser')

# Close the browser
driver.quit()

clinic_elems = soup500.find_all('div', class_='c-estb-card')
#clinic_elems = soup1.find(class_='c-estb-card')

clinics_data = []

for clinic_elem in clinic_elems:
    clinic = {}
    
    # Extract name
    name_elem = clinic_elem.find('a', class_='line-1')
    clinic['Hospital Name'] = name_elem.text.strip() if name_elem else None
    
    # Extract name
    url_elem = clinic_elem.find('a', href=True)
    href = url_elem['href']
    #if "practo.com" in href and "clinic" in href:
    clinic['URL'] = requests.compat.urljoin(url, href).replace("?referrer=clinic_listing", "")
    
    
    clinics_data.append(clinic)


df = pd.DataFrame(clinics_data)

df

# Convert the DataFrame to a CSV file
csv_file_path = 'hyderabad_hosp_list.csv'  # Specify the file name and path
df.to_csv(csv_file_path, index=False)  # Set index=False to exclude row numbers


# Serialize the BeautifulSoup object to a string
soup_string = str(soup500)

# Specify the file path
file_path = 'soup_18330.html'

# Save the string to a file
with open(file_path, 'w', encoding='utf-8') as file:
    file.write(soup_string)
